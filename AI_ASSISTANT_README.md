# AI-Powered Financial Assistant

This document describes the AI-powered financial assistant feature integrated into the Feza Logistics financial management system.

## Overview

The AI assistant uses TinyLlama via Ollama to provide natural language query capabilities for financial data. It can answer questions, generate reports, and provide insights by converting natural language questions into safe SQL queries.

## Features

- **Natural Language Queries**: Ask questions in plain English about financial data
- **Real-time Responses**: Get instant answers from your database
- **SQL Transparency**: See the SQL queries generated by the AI
- **Security First**: Only SELECT queries are allowed; all modification commands are blocked
- **Audit Trail**: All interactions are logged for security and compliance
- **Session-based History**: Chat history is maintained within user sessions
- **Responsive Design**: Works seamlessly on desktop and mobile devices

## Prerequisites

### 1. Ollama Installation

Ollama must be installed and running on the server. Install Ollama by following the instructions at: https://ollama.ai

```bash
# Install Ollama (Linux/macOS)
curl -fsSL https://ollama.ai/install.sh | sh

# Start Ollama service
ollama serve
```

### 2. TinyLlama Model

Pull the TinyLlama model:

```bash
ollama pull tinyllama
```

### 3. Database Migration

Apply the AI chat logs migration:

```bash
mysql -u your_username -p duns < migrations/004_create_ai_chat_logs_table.sql
```

## Configuration

The AI assistant is configured in `ai_assistant.php` with the following settings:

- **Ollama API URL**: `http://localhost:11434/api/generate` (default)
- **Model**: `tinyllama`
- **Max Response Tokens**: 500
- **SQL Timeout**: 5 seconds
- **Temperature**: 0.1 (for deterministic SQL generation)

To modify these settings, edit the constants at the top of `ai_assistant.php`:

```php
define('OLLAMA_API_URL', 'http://localhost:11434/api/generate');
define('OLLAMA_MODEL', 'tinyllama');
define('MAX_RESPONSE_TOKENS', 500);
define('SQL_TIMEOUT', 5);
```

## Usage

### Accessing the AI Assistant

1. Log in to the financial management system
2. Navigate to the dashboard (index.php)
3. Click the floating chat button in the bottom-right corner
4. Start asking questions!

### Example Queries

- "Show me total revenue for this month"
- "How many unpaid invoices do we have?"
- "List top 5 clients by revenue"
- "What is our total outstanding amount in USD?"
- "Show me all clients who paid in EUR this year"
- "How many new clients were added this week?"
- "What's the average invoice amount?"

### Quick Questions

The chat widget includes pre-defined quick questions to get started:
- ðŸ“Š Show total revenue this month
- ðŸ’° Show unpaid invoices
- ðŸ‘¥ Top clients by revenue
- ðŸ’µ Outstanding amount in USD

## Security

### Authentication
- Only logged-in users can access the AI assistant
- Unauthenticated requests return a 401 Unauthorized error

### SQL Validation
The system implements multiple layers of SQL validation:

1. **Query Type Restriction**: Only SELECT queries are allowed
2. **Keyword Blocking**: Dangerous keywords (INSERT, UPDATE, DELETE, DROP, ALTER, etc.) are blocked
3. **Result Limiting**: All queries automatically include a LIMIT clause (max 100 rows)
4. **Prepared Statements**: All SQL is executed using PDO prepared statements
5. **Exception Handling**: Database errors are caught and sanitized before being shown to users

### Audit Logging
All AI interactions are logged in the `ai_chat_logs` table with:
- User ID and session ID
- User query and AI response
- SQL query executed
- Result count and execution time
- Status (success/error/blocked)
- Error messages (if any)

## Database Schema

### ai_chat_logs Table

| Column | Type | Description |
|--------|------|-------------|
| id | INT | Primary key |
| user_id | INT | Foreign key to users table |
| session_id | VARCHAR(255) | Chat session identifier |
| user_query | TEXT | User's natural language query |
| ai_response | TEXT | AI assistant's response |
| sql_executed | TEXT | SQL query executed |
| sql_result_count | INT | Number of rows returned |
| execution_time_ms | INT | Query execution time in milliseconds |
| status | ENUM | success, error, or blocked |
| error_message | TEXT | Error details if applicable |
| created_at | TIMESTAMP | Timestamp of interaction |

## Files Structure

```
/home/runner/work/duns/duns/
â”œâ”€â”€ ai_assistant.php              # Backend API for AI assistant
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ ai-chat.css          # Chat widget styles
â”‚   â””â”€â”€ js/
â”‚       â””â”€â”€ ai-chat.js           # Chat widget JavaScript
â”œâ”€â”€ migrations/
â”‚   â””â”€â”€ 004_create_ai_chat_logs_table.sql  # Database migration
â””â”€â”€ index.php                     # Dashboard with integrated chat widget
```

## Troubleshooting

### Ollama Connection Issues

If you get "Failed to connect to Ollama" errors:

1. Verify Ollama is running:
   ```bash
   curl http://localhost:11434/api/tags
   ```

2. Check if TinyLlama is installed:
   ```bash
   ollama list
   ```

3. Restart Ollama service:
   ```bash
   pkill ollama
   ollama serve
   ```

### Performance Issues

If responses are slow:

1. **Reduce max tokens**: Lower `MAX_RESPONSE_TOKENS` in `ai_assistant.php`
2. **Use GPU**: Configure Ollama to use GPU acceleration if available
3. **Optimize queries**: Add appropriate database indexes
4. **Keep model loaded**: Ollama keeps models in memory after first use

### Database Errors

If you see SQL execution errors:

1. Check database connection in `db.php`
2. Verify the user has SELECT permissions on all tables
3. Review the SQL query in the chat response (shown below AI responses)
4. Check `ai_chat_logs` table for detailed error messages

## Performance Optimization

### Keeping Ollama Running

To ensure Ollama stays running and keeps the model loaded:

```bash
# Add Ollama as a systemd service (Linux)
sudo systemctl enable ollama
sudo systemctl start ollama
```

### Database Indexes

The system already includes optimized indexes on:
- `clients`: reg_no, client_name, phone_number
- `ai_chat_logs`: user_id, session_id, created_at

### Caching (Future Enhancement)

Consider implementing caching for frequently asked questions:
- Cache common aggregate queries (totals, counts)
- Store cache in Redis or similar
- Invalidate cache on data modifications

## Known Limitations

1. **Model Capability**: TinyLlama is a small model and may occasionally generate incorrect SQL
2. **Complex Queries**: Very complex multi-table joins may not work reliably
3. **Natural Language Understanding**: The AI works best with clear, specific questions
4. **Language Support**: Currently optimized for English queries only

## Future Enhancements

Potential improvements for future versions:

- [ ] PDF report generation via AI commands
- [ ] Voice input support
- [ ] Multi-language support
- [ ] Query result visualization (charts, graphs)
- [ ] AI-suggested queries based on user behavior
- [ ] Integration with document generation
- [ ] Email report scheduling via chat
- [ ] Advanced analytics and forecasting

## Support

For issues or questions about the AI assistant:
1. Check the `ai_chat_logs` table for error details
2. Review Ollama logs: `journalctl -u ollama -f`
3. Contact the development team

## License

This feature is part of the Feza Logistics financial management system.
